---
layout:     post
title:      The Hidden Surveillance
author:     Camdan Mead
date:       2025-11-2 01:00:00
summary:    An argument that modern surveillance has evolved from passive data collection into an active system of behavioral prediction and manipulation that erodes human autonomy, a threat that can only be countered by widespread public awareness.
categories:
listed:     false
---

**"You are now less valuable than the data you produce."**

When the video game *Watch Dogs 2* opened with this line in 2016, it felt like a cynical, slightly satirical comment on the present state of tech. The line, and the opening video it comes from, wasn't intended to do much more than set the scene and introduce the world. *Watch Dogs* tells a story of hackers combating a fictional operating system called ctOS that harvests citizen data to predict, manage, and manipulate them. Things like predictive policing, algorithmic loan denials, and social score-style "threat" scoring were all just plot points.

<center><iframe width="560" height="315" src="https://www.youtube.com/embed/scyA9cnbja4" frameborder="0" allowfullscreen></iframe></center>

Today, less than a decade later, the satire has evaporated. The game's core premise doesn't feel like a dystopian warning anymore. It feels like a documentary.

For decades, our understanding of surveillance was shaped by the 20th century. We picture trench coats, government agents, and listening devices in briefcases. The 21st-century reality is far more subtle, and far more pervasive. The surveillance isn't happening in black vans. It's happening in the devices in our pockets (or worn on our bodies), the smart speakers on our counters, and the "Accept Cookies" banners we click past every day.

We've heard the adage, "if you're not paying for the product, you are the product." But this saying is now dangerously outdated. It minimizes the problem by framing it as a simple, fair transaction. We trade our attention for a service. For most people, this is a small compromise, a small price to pay. The reality, though, is a different type of transaction. Your data isn't just being collected to sell you sneakers. It's being used to build a profile so detailed it can predict your behavior, and then, more importantly, change it. Your behavior is enormously profitable. You are not the product anymore. The real product is the behavioral prediction, the certainty of your future actions, sold to the highest bidder.

> Your behavior is enormously profitable.

This shift from passive collection to active behavioral modification has become a system that quietly erodes personal autonomy, manipulates social discourse, and creates unprecedented power imbalances, often through a hidden partnership between governmental and private surveillance.

This problem is systemic, but it is not unsolvable. What we need is a fundamental change in public awareness.

## Three Layers of Digital Control
In the digital age, control is exerted through three interconnected layers: data collection, behavioral prediction, and behavioral manipulation. Each layer builds upon the last, creating a comprehensive system of surveillance that extends into every aspect of our lives.

### From Prediction to Manipulation

The goal of this new economy is no longer just to predict what you will buy, it is to actively influence what you will do, think, and feel. This is the core of what scholar Shoshana Zuboff calls "surveillance capitalism".[^1] It is the practice of claiming private human experience as a free source of raw material, which is then used to create "prediction products" that are sold to the highest bidder.

<center><iframe width="560" height="315" src="https://www.youtube.com/embed/8HzW5rzPUy8" frameborder="0" allowfullscreen></iframe></center>

Consider the algorithmic feeds of platforms like TikTok or Instagram. These systems don't just find content you'll like, they actively shape your preferences over time. The algorithm serves you a video, measures your precise engagement, and refines its model of you. This isn't a passive library that merely adapts to you, it's an active behavioral feedback loop, a machine designed to hold your attention for the maximum possible time, often by nudging you toward more extreme or emotionally charged content.[^2] [^3]

> It's a machine designed to hold your attention for the maximum possible time.

And this extends beyond social media. It's the dynamic pricing on a travel site that triples the cost of a flight because it knows your search history implies you're in a hurry, or shows you more expensive hotels because it suspects you may have a higher purchasing power.[^4] It's the "wellness" app that shares your sleep data[^5] with your insurance provider, which then "nudges" you with higher premiums to encourage healthier (and less risky) behavior. You are no longer the customer. As Zuboff puts it, you are now the raw material.

![Dynamic Pricing Illustration](/assets/hidden-surveillence/dynamicpricing.avif)
*Image Credit: [Paddle](https://www.paddle.com/blog/dynamic-pricing-strategy)*

### The Corporate-State Surveillance Partnership

The most dangerous surveillance, however, occurs where this corporate data collection meets government power, and entirely leaves the realm of your control. This is the new unavoidable life surveillance.

Companies like Palantir build the sophisticated data analysis tools that allow intelligence agencies like the CIA and NSA to sift through the mountains of data corporations collect.[^6] They are the crucial, often invisible bridge between the private sector's efficiency and the state's power.

This partnership is no longer just digital. Companies like Flock Safety are building a massive, private surveillance network of license plate readers and CCTV cameras across the country.[^7] This network is sold as a subscription service directly to local law enforcement (or even private companies), often with little to no public oversight or debate. Contrary to the prediction of *Watch Dogs*, this isn't a "smart city" run by the public; it's a privately owned surveillance dragnet layered on top of our physical world.[^8]

![Flock Safety Camera](/assets/hidden-surveillence/flockcamera.jpeg)
*Image Credit: [Flock Safety](https://www.flocksafety.com/ebooks/license-plate-reader-cameras-overview)*

This corporate collaboration is especially alarming in light of Edward Snowden's 2013 revelations, where he blew the whistle on the NSA's enormous digital spying operation on every american. Snowden established a public baseline for what we know the government is capable of and, more importantly, what it *wants* to do.[^9] Now, the private sector is building an even more comprehensive surveillance machine, and state agencies are its eager customers.

Of course, we've heard (or maybe even made) the classic counterargument: "I have nothing to hide, so why should I care?" This argument fundamentally misunderstands the purpose of privacy. Privacy is not about hiding wrongdoing; it's about the freedom to be oneself without judgment, the autonomy to explore ideas, and the right to make mistakes without a permanent, searchable record. Perfectly legal behavior, such as attending a protest, visiting a medical specialist, or researching a sensitive topic, can be used to build a profile that limits your opportunities, raises your insurance rates, places you on a watchlist, or even manipulates your behavior.

> Privacy is not about hiding wrongdoing; it's about the freedom to be oneself without judgment.

Privacy is the space we need to be fully human.

Understanding the motives behind this is simple. In order for a company to be successful, in one way or another, money must flow from you to them. In any transaction, any interaction, the party with more information always has the upper hand. Giving away your data isn't just giving up privacy; it's giving away your power.

### The Manipulation of Society

What starts as commercial manipulation doesn't stay there. These tools are too powerful to remain in the realm of advertising. The same mechanisms used to sell products are now used to sell ideologies, influence elections, and deepen social divides.

The most infamous example is the Cambridge Analytica scandal.[^10] The firm harvested the Facebook data of millions to build detailed psychographic profiles, which were then used to target voters with bespoke, emotionally-charged political messages during the 2016 U.S. election. This wasn't a debate. It was a mass-scale, targeted psychological operation.

![Filter Bubbles Illustration](/assets/hidden-surveillence/filterbubbles.png)
*Image Credit: [Evelyn Lo](https://loevelyn.wordpress.com/2017/11/17/lets-break-out-of-this-echo-chamber/)*

This political manipulation is supercharged by the "filter bubbles" and "echo chambers" these platforms are built to create.[^11] Algorithms are not designed to inform you; they are designed to engage you. Engagement, they've learned, is highest when we are either validated or outraged. This creates a feedback loop that pushes users toward more extreme versions of their existing beliefs, polarizing public discourse and making good-faith debate nearly impossible. And these tools are not just for corporations. A polarized, outraged, and divided populace is also a populace that is easier to manage and harder to rally against systemic overreach.

> Algorithms are not designed to inform you; they are designed to engage you.

## The Solutions: Reclaiming Our Digital World

This problem feels impossibly large, but the solutions are not purely technological. They are, above all, human.

### A Flawed Hope of Legislative Action

The most obvious solution is to pass robust legislation. We could look to policies like Europe's General Data Protection Regulation (GDPR), which grants citizens their right to be forgotten and right to data portability. They're strong, and generally speaking, relatively effective when enforced properly. So, why haven't these solutions materialized in the United States?

The simple truth is that government action is a flawed hope. First, and most obviously, the power of corporate lobbying is immense, and tech companies spend billions to ensure no meaningful regulation is passed.[^12] Second, the pace of legislation is glacial, while technology advances exponentially. By the time a law is passed, the technology it was meant to regulate is already obsolete. Finally, there is a profound and persistent lack of technical understanding among many policymakers, something we saw over and over again during the infamous TikTok hearings, where senators struggled to grasp basic technological concepts.[^13] We cannot, and should not, wait for legislative salvation.

### Personal Technical Countermeasures

A more personal solution lies in the tools we choose to use. A growing ecosystem of privacy-respecting software exists, from end-to-end encrypted messaging apps to search engines that don't track you. Making the conscious choice to use these tools is a form of personal resistance, and certainly goes a long way.

However, this is a technological arms race. Take quantum computing, for example. Even our best encryption methods are under threat. Security researchers are already working on "quantum-safe" encryption to defend against the threat of future quantum computers. Even though quantum computers with enough power to be useful outside of research are, by generous estimates, a decade out, data can simply be collected and stored now to be decrypted later. Malicious actors can steal vast amounts of encrypted data today and simply sit on it, waiting for the technology to exist that can crack it open.[^14]

No purely technological solution is final.

### Public Awareness & Digital Literacy

The real, sustainable solution is not in our laws or our software, but in our minds. The ultimate answer is a cultural shift, driven by public awareness and digital literacy. We have to stop passively accepting these "services" as free and start seeing them for what they are: an extractive industry.

> The ultimate answer is a cultural shift.

This isn't just about "reading the privacy policy." It's about developing an instinctive skepticism. It involves educating ourselves and others on how this system *actually* works. It's understanding that when a service is free, you are not the customer, you are the resource being mined. It means learning to identify "dark patterns," the manipulative design choices in apps and websites that nudge us to share more data or take unintended actions.[^15] It means recognizing that the "recommendation" you just received wasn't a helpful suggestion, it was a calculated promotion.

![Dark Patterns Illustration](/assets/hidden-surveillence/darkpatterns.avif)
*Image Credit: [Toptal](https://www.toptal.com/designers/ux/dark-patterns)*

The current system is driven by profit. Therefore, the only way to change it is to make privacy profitable. When a critical mass of users understands the value of their own data and begins to demand and *choose* privacy, companies will be forced to compete on it. This is the only solution that flips the incentive structure.

### More Than Just Data

The fight we are in is not just about data. It's about preserving human agency in an increasingly automated world. It's a fight for the right to self-determination, to have a thought that is not predicted, and to make a choice that is not nudged.

If we are currently less valuable than our data, these solutions, starting with our own awareness, are the only path to reversing that equation. The goal is to build a future where technology serves humanity, not the other way around.

---

## References

[^1]: Zuboff, Shoshana. (2019). *The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power*. PublicAffairs.

[^2]: Center for Humane Technology. (n.d.). "Ledger of Harms." Retrieved November 2, 2025, from [https://ledger.humanetech.com/](https://ledger.humanetech.com/)

[^3]: Husz√°r, F., et al. (2022). "Algorithmic amplification of political content on Twitter." *Proceedings of the National Academy of Sciences (PNAS)*. [https://www.pnas.org/doi/full/10.1073/pnas.2025334119](https://www.pnas.org/doi/full/10.1073/pnas.2025334119)

[^4]: Mattioli, Dana. (2012, December 24). "On Orbitz, Mac Users Steered to Pricier Hotels." *The Wall Street Journal*. [https://www.wsj.com/articles/SB10001424052702304458604577488822667325882](https://www.wsj.com/articles/SB10001424052702304458604577488822667325882)

[^5]: Gero, K. (2023, April 20). "Mental Health Apps Are Not Keeping Your Data Safe." *Scientific American*. [https://www.scientificamerican.com/article/mental-health-apps-are-not-keeping-your-data-safe/](https://www.scientificamerican.com/article/mental-health-apps-are-not-keeping-your-data-safe/)

[^6]: Mye, R., & Gallagher, R. (2018, April 19). "Palantir Knows Everything About You." *Bloomberg Businessweek*. [https://www.bloomberg.com/features/2018-palantir-peter-thiel/](https://www.bloomberg.com/features/2018-palantir-peter-thiel/)

[^7]: Electronic Frontier Foundation (EFF). (2025, September 23). "EFF Urges Virginia Court of Appeals to Require Search Warrants to Access ALPR Databases." [https://www.eff.org/deeplinks/2025/09/eff-urges-virgina-court-appeals-require-search-warrants-access-alpr-databases](https://www.eff.org/deeplinks/2025/09/eff-urges-virgina-court-appeals-require-search-warrants-access-alpr-databases)

[^8]: Wiggers, K. (2022, April 11). "Police cameras scan billions of license plates a month, sparking protests." *NBC News*. [https://www.nbcnews.com/tech/tech-news/flock-police-cameras-scan-billions-month-sparking-protests-rcna230037](https://www.nbcnews.com/tech/tech-news/flock-police-cameras-scan-billions-month-sparking-protests-rcna230037)

[^9]: Greenwald, Glenn. (2014). *No Place to Hide: Edward Snowden, the NSA, and the U.S. Surveillance State*. Metropolitan Books.

[^10]: Cadwalladr, C., & Graham-Harrison, E. (2018, March 17). "Revealed: 50 million Facebook profiles harvested for Cambridge Analytica in major data breach." *The Guardian*. [https://www.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence-us-election](https://www.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence-us-election)

[^11]: Pariser, Eli. (2011). *The Filter Bubble: What the Internet Is Hiding from You*. Penguin Press.

[^12]: OpenSecrets. (2024). "Computers/Internet: Top Spenders." [https://www.opensecrets.org/industries/lobbying?cycle=2024&ind=B13](https://www.opensecrets.org/industries/lobbying?cycle=2024&ind=B13)

[^13]: Lecher, C. (2023, March 24). "Congress's TikTok hearing was an aggressive, useless mess." *The Verge*. [https://www.theverge.com/2023/3/24/23654831/tiktok-congressional-hearing-xenophobia-china](https://www.theverge.com/2023/3/24/23654831/tiktok-congressional-hearing-xenophobia-china)

[^14]: QuantumXC. (2024, May 14). "Harvest Now, Decrypt Later (HNDL): The Quantum Computing Threat to Data Security." [https://quantumxc.com/blog/harvest-now-decrypt-later/](https://quantumxc.com/blog/harvest-now-decrypt-later/)

[^15]: Federal Trade Commission (FTC). (2022, September). "Bringing Dark Patterns to Light." [PDF Report]. [https://www.ftc.gov/system/files/ftc_gov/pdf/P214800+Dark+Patterns+Report+9.14.2022+-+FINAL.pdf](https://www.ftc.gov/system/files/ftc_gov/pdf/P214800+Dark+Patterns+Report+9.14.2022+-+FINAL.pdf)
